{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc02a877",
   "metadata": {},
   "source": [
    "# Address Matching: EDA & Normalization\n",
    "Bu notebook, **adres veri seti** için keşifsel veri analizi (EDA) ve normalizasyon ön incelemelerini içerir.\n",
    "\n",
    "**İçerik:**\n",
    "1) Kurulum & Yol Ayarları\n",
    "2) Veriyi Yükleme ve İlk Bakış\n",
    "3) Karakter/Uzunluk İstatistikleri\n",
    "4) Token Frekansları ve Kısaltmalar\n",
    "5) İdari Token Kapsaması\n",
    "6) Label Dağılımı\n",
    "7) Yakın-Duplicate Keşfi (Jaccard n-gram)\n",
    "8) Normalizasyon Önizlemesi\n",
    "\n",
    "> Not: Büyük veri sebebiyle bazı analizler örnekleme ile çalışır. `SAMPLE_SIZE` değişkenini ayarlayabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Kurulum & Yol Ayarları\n",
    "import os, re, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from typing import List, Dict\n",
    "\n",
    "# Proje yolları\n",
    "TRAIN_PATH = \"/mnt/data/train.csv\"   # kendi dizinine göre değiştir\n",
    "OUTPUT_DIR = \"./artifacts/eda\"       # notebook köküne göre\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Örnekleme\n",
    "SAMPLE_SIZE = 200000  # hız için; tüm veri için 0 yap\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Helper modüller\n",
    "import sys\n",
    "sys.path.append(\"./lib\")  # aynı notebook klasöründeki lib/\n",
    "from normalize_address import normalize_address\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0546db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Veriyi Yükleme ve İlk Bakış\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "if SAMPLE_SIZE and SAMPLE_SIZE > 0 and SAMPLE_SIZE < len(df):\n",
    "    df = df.sample(SAMPLE_SIZE, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "assert {\"address\",\"label\"}.issubset(df.columns), \"train.csv 'address' ve 'label' sütunları içermeli.\"\n",
    "\n",
    "display(df.head(5))\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Unique address:\", df['address'].nunique())\n",
    "print(\"Unique label:\", df['label'].nunique())\n",
    "print(\"Missing % (address, label):\", df['address'].isna().mean()*100, df['label'].isna().mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Karakter/Uzunluk İstatistikleri\n",
    "def char_stats(series: pd.Series) -> pd.DataFrame:\n",
    "    lengths = series.str.len()\n",
    "    digits = series.str.count(r\"\\d\")\n",
    "    alphas = series.str.count(r\"[A-Za-zÇĞİÖŞÜçğıöşü]\")\n",
    "    spaces = series.str.count(r\"\\s\")\n",
    "    puncts = series.str.count(r\"[^\\w\\sçğıöşüÇĞİÖŞÜ]\")\n",
    "    return pd.DataFrame({\n",
    "        \"len\": lengths,\n",
    "        \"digits\": digits,\n",
    "        \"alphas\": alphas,\n",
    "        \"spaces\": spaces,\n",
    "        \"puncts\": puncts,\n",
    "        \"digit_ratio\": (digits / lengths).replace([np.inf, np.nan], 0),\n",
    "        \"alpha_ratio\": (alphas / lengths).replace([np.inf, np.nan], 0),\n",
    "        \"space_ratio\": (spaces / lengths).replace([np.inf, np.nan], 0),\n",
    "        \"punct_ratio\": (puncts / lengths).replace([np.inf, np.nan], 0),\n",
    "    })\n",
    "\n",
    "cstats = char_stats(df[\"address\"])\n",
    "display(cstats.describe(percentiles=[.05,.25,.5,.75,.95]))\n",
    "cstats.describe().to_csv(os.path.join(OUTPUT_DIR, \"01_char_stats_describe.csv\"))\n",
    "\n",
    "extreme = pd.concat([\n",
    "    df.loc[cstats[\"len\"] <= 15, [\"address\", \"label\"]].head(50),\n",
    "    df.loc[cstats[\"len\"] >= 150, [\"address\", \"label\"]].head(50),\n",
    "])\n",
    "extreme.to_csv(os.path.join(OUTPUT_DIR, \"01b_extreme_lengths_samples.csv\"), index=False)\n",
    "print(\"Saved: 01_char_stats_describe.csv & 01b_extreme_lengths_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e67d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Token Frekansları ve Kısaltmalar\n",
    "import re\n",
    "RE_WS = re.compile(r\"\\s+\")\n",
    "RE_PUNCT = re.compile(r\"[^\\w\\sçğıöşüÇĞİÖŞÜ/.,-]\")\n",
    "RE_TOKEN = re.compile(r\"[A-Za-zÇĞİÖŞÜçğıöşü0-9./-]+\")\n",
    "\n",
    "ABBREV_MAP = {\n",
    "    \"mah\": \"mahalle\",\"mh\": \"mahalle\",\"mah.\": \"mahalle\",\"mahallesi\":\"mahalle\",\n",
    "    \"cad\": \"caddesi\",\"cd\":\"caddesi\",\"cad.\":\"caddesi\",\"cadd.\":\"caddesi\",\"caddesi\":\"caddesi\",\n",
    "    \"sk\":\"sokak\",\"sk.\":\"sokak\",\"sok\":\"sokak\",\"sok.\":\"sokak\",\n",
    "    \"blv\":\"bulvarı\",\"blv.\":\"bulvarı\",\"bulv.\":\"bulvarı\",\"bulv\":\"bulvarı\",\"bulvari\":\"bulvarı\",\"bulvar\":\"bulvarı\",\n",
    "    \"no\":\"no\",\"no.\":\"no\",\"kat.\":\"kat\",\"daire\":\"daire\",\"dr.\":\"doktor\"\n",
    "}\n",
    "\n",
    "def tr_lower(s: str) -> str:\n",
    "    return s.replace(\"I\",\"ı\").replace(\"İ\",\"i\").lower()\n",
    "\n",
    "def basic_clean(s: str) -> str:\n",
    "    s = tr_lower(str(s))\n",
    "    s = RE_PUNCT.sub(\" \", s)\n",
    "    s = RE_WS.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def expand_abbrev(tokens):\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        t0 = t.strip(\".\")\n",
    "        out.append(ABBREV_MAP.get(t, ABBREV_MAP.get(t0, t)))\n",
    "    return out\n",
    "\n",
    "def tokenize(s: str):\n",
    "    return RE_TOKEN.findall(s)\n",
    "\n",
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for s in df[\"address\"]:\n",
    "    toks = expand_abbrev(tokenize(basic_clean(s)))\n",
    "    cnt.update(toks)\n",
    "\n",
    "top_tokens = pd.DataFrame(cnt.most_common(200), columns=[\"token\",\"freq\"])\n",
    "display(top_tokens.head(20))\n",
    "top_tokens.to_csv(os.path.join(OUTPUT_DIR, \"02_top_tokens.csv\"), index=False)\n",
    "print(\"Saved: 02_top_tokens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) İdari Token Kapsaması\n",
    "ADMIN_TOKENS = {\"mahalle\",\"caddesi\",\"sokak\",\"bulvarı\",\"no\",\"kat\"}\n",
    "\n",
    "rows = []\n",
    "for s in df[\"address\"]:\n",
    "    toks = set(expand_abbrev(tokenize(basic_clean(s))))\n",
    "    rows.append({f\"has_{t}\": (t in toks) for t in ADMIN_TOKENS})\n",
    "cov = pd.DataFrame(rows).mean().rename(\"coverage\").to_frame()\n",
    "display(cov)\n",
    "cov.to_csv(os.path.join(OUTPUT_DIR, \"03_admin_token_coverage.csv\"))\n",
    "print(\"Saved: 03_admin_token_coverage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Label Dağılımı\n",
    "vc = df[\"label\"].value_counts()\n",
    "top_labels = vc.head(20).rename_axis(\"label\").reset_index(name=\"count\")\n",
    "diversity = 1.0 - np.sum((vc / vc.sum()) ** 2)  # Gini-like\n",
    "\n",
    "display(top_labels)\n",
    "print(\"Label diversity ~\", round(diversity,4))\n",
    "\n",
    "top_labels.to_csv(os.path.join(OUTPUT_DIR, \"04_top_labels.csv\"), index=False)\n",
    "with open(os.path.join(OUTPUT_DIR, \"04_label_diversity.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Gini-like diversity (1=dağılım çeşitli): {diversity:.4f}\\n\")\n",
    "print(\"Saved: 04_top_labels.csv / 04_label_diversity.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cf773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Yakın-Duplicate Keşfi (Jaccard 3-gram)\n",
    "def char_ngrams(s, n=3):\n",
    "    s = basic_clean(s).replace(\" \",\"\")\n",
    "    return {s[i:i+n] for i in range(max(0, len(s)-n+1))}\n",
    "\n",
    "SAMPLE_FOR_DUP = min(20000, len(df))\n",
    "sample_series = df[\"address\"].sample(SAMPLE_FOR_DUP, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "grams = [char_ngrams(s, n=3) for s in sample_series]\n",
    "\n",
    "pairs = []\n",
    "thr = 0.90\n",
    "for i in range(len(sample_series)):\n",
    "    gi = grams[i]\n",
    "    for j in range(i+1, min(i+200, len(sample_series))):\n",
    "        gj = grams[j]\n",
    "        inter = len(gi & gj); uni = len(gi | gj)\n",
    "        jacc = inter/uni if uni else 0.0\n",
    "        if jacc >= thr:\n",
    "            pairs.append((sample_series[i], sample_series[j], jacc))\n",
    "\n",
    "dup_df = pd.DataFrame(pairs, columns=[\"addr_a\",\"addr_b\",\"jaccard\"])\n",
    "display(dup_df.head(20))\n",
    "dup_df.head(200).to_csv(os.path.join(OUTPUT_DIR, \"05_near_duplicates_samples.csv\"), index=False)\n",
    "print(\"Saved: 05_near_duplicates_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfffb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Normalizasyon Önizlemesi\n",
    "preview = df.sample(200, random_state=7).copy()\n",
    "preview[\"address_norm\"] = preview[\"address\"].astype(str).apply(normalize_address)\n",
    "display(preview.head(10)[[\"address\",\"address_norm\",\"label\"]])\n",
    "preview.to_csv(os.path.join(OUTPUT_DIR, \"06_normalization_preview.csv\"), index=False)\n",
    "print(\"Saved: 06_normalization_preview.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
