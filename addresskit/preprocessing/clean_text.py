import unicodedata
from typing import Dict, Tuple
import regex as re

# Regexler
WHITESPACE_RE = re.compile(r"\s+")
PUNCT_RE = re.compile(r"[^\w\sÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ.-]")  # nokta/tireyi ÅŸimdilik koru

def tr_lower(s: str) -> str:
    """TÃ¼rkÃ§e-safe lower"""
    return (s.replace("I", "Ä±").replace("Ä°", "i")).lower()

def strip_punct(s: str) -> str:
    """Noktalama iÅŸaretlerini (nokta/tire hariÃ§) boÅŸlukla deÄŸiÅŸtir"""
    return PUNCT_RE.sub(" ", s)

def collapse_ws(s: str) -> str:
    """Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa indir ve baÅŸ/son boÅŸluklarÄ± sil"""
    return WHITESPACE_RE.sub(" ", s).strip()

def ascii_fold(s: str) -> str:
    """TÃ¼rkÃ§e karakterleri ASCII karÅŸÄ±lÄ±ÄŸÄ±na Ã§evir"""
    return unicodedata.normalize("NFKD", s).encode("ascii", "ignore").decode("ascii")

def load_config(cfg: Dict) -> Dict:
    """Config dosyasÄ±nÄ± yÃ¼kler"""
    return cfg

def expand_abbreviations(s: str, cfg: Dict) -> str:
    """KÄ±saltmalarÄ± geniÅŸletir"""
    for canon, alts in cfg.get("expand_abbr", {}).items():
        canon_str = str(canon)  # ğŸ”¹ Tip gÃ¼venliÄŸi
        for a in alts:
            s = re.sub(rf"\b{re.escape(str(a))}\b", canon_str, s)
    return s

def canonicalize_terms(s: str, cfg: Dict) -> str:
    """Terimleri canonical forma Ã§evirir"""
    for raw, canon in cfg.get("canonical_map", {}).items():
        s = re.sub(rf"\b{re.escape(str(raw))}\b", str(canon), s)
    return s

def remove_terms(s: str, cfg: Dict) -> str:
    """Belirli kelimeleri metinden Ã§Ä±karÄ±r"""
    for t in cfg.get("remove_terms", []):
        s = re.sub(rf"\b{re.escape(str(t))}\b", " ", s)
    return s

def normalize_text(text: str, cfg: Dict) -> Tuple[str, str]:
    """
    Adresi normalize eder.
    DÃ¶nÃ¼ÅŸ: (primary_norm, secondary_ascii_norm)
    """
    # ğŸ”¹ Tip gÃ¼venliÄŸi: adres string deÄŸilse string'e Ã§evir
    if not isinstance(text, str):
        text = "" if text is None else str(text)

    s = text or ""
    if cfg.get("lowercase", True):
        s = tr_lower(s)
    if cfg.get("strip_punct", True):
        s = strip_punct(s)
    s = expand_abbreviations(s, cfg)
    s = canonicalize_terms(s, cfg)
    s = remove_terms(s, cfg)
    if cfg.get("collapse_spaces", True):
        s = collapse_ws(s)

    if cfg.get("ascii_fold_secondary", False):
        s2 = ascii_fold(s)
        s2 = collapse_ws(s2)
    else:
        s2 = s

    return s, s2

def extract_parts(s: str, cfg: Dict) -> Dict[str, str]:
    """
    Regex tabanlÄ± parÃ§a Ã§Ä±karÄ±mÄ±
    """
    out = {}
    parts = cfg.get("parts", {})
    for key, pat in parts.items():
        m = re.search(pat, s)
        if m:
            out[key] = collapse_ws(m.group(1))
    # KapÄ± numarasÄ±, daire, kat gibi yaygÄ±n parÃ§alar
    if "no" not in out:
        m = re.search(r"\bno\s*([0-9]{1,5}[A-Za-z]?)\b", s)
        if m:
            out["no"] = m.group(1)
    if "daire" not in out:
        m = re.search(r"\bdaire\s*([0-9]{1,5}[A-Za-z]?)\b", s)
        if m:
            out["daire"] = m.group(1)
    if "kat" not in out:
        m = re.search(r"\bkat\s*([0-9]{1,3})\b", s)
        if m:
            out["kat"] = m.group(1)
    return out
